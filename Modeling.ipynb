{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import splitfolders\n",
    "import numpy as np\n",
    "from keras import models, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain & Pre-Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform train test split on image folders for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Copying files: 0 files [00:00, ? files/s]\u001b[A\n",
      "Copying files: 106 files [00:00, 1055.18 files/s]\u001b[A\n",
      "Copying files: 232 files [00:00, 1098.57 files/s]\u001b[A\n",
      "Copying files: 350 files [00:00, 1120.27 files/s]\u001b[A\n",
      "Copying files: 477 files [00:00, 1161.09 files/s]\u001b[A\n",
      "Copying files: 584 files [00:00, 1130.06 files/s]\u001b[A\n",
      "Copying files: 713 files [00:00, 1136.23 files/s]\u001b[A\n",
      "Copying files: 856 files [00:00, 1210.53 files/s]\u001b[A\n",
      "Copying files: 992 files [00:00, 1249.30 files/s]\u001b[A\n",
      "Copying files: 1140 files [00:00, 1308.88 files/s]\u001b[A\n",
      "Copying files: 1274 files [00:01, 1316.51 files/s]\u001b[A\n",
      "Copying files: 1404 files [00:01, 1237.04 files/s]\u001b[A\n",
      "Copying files: 1528 files [00:01, 1085.72 files/s]\u001b[A\n",
      "Copying files: 1640 files [00:01, 1093.60 files/s]\u001b[A\n",
      "Copying files: 1752 files [00:01, 1099.69 files/s]\u001b[A\n",
      "Copying files: 1896 files [00:01, 1183.48 files/s]\u001b[A\n",
      "Copying files: 2018 files [00:01, 1146.14 files/s]\u001b[A\n",
      "Copying files: 2188 files [00:01, 1174.14 files/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "input_folder = 'Data/class_data'\n",
    "output_folder = 'Data/ttsplit_data'\n",
    "classes = ['paper', 'rock', 'scissors']\n",
    "\n",
    "splitfolders.ratio(input_folder, output=output_folder, seed=37, ratio=(.64, .2, .16))\n",
    "\n",
    "# train val test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine batch size of images from all 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1399\n",
      "352\n",
      "437\n"
     ]
    }
   ],
   "source": [
    "train_folder = 'Data/ttsplit_data/train'\n",
    "test_folder = 'Data/ttsplit_data/test'\n",
    "val_folder = 'Data/ttsplit_data/val'\n",
    "classes = ['paper', 'rock', 'scissors']\n",
    "\n",
    "train_imgs = []\n",
    "test_imgs = []\n",
    "val_imgs = []\n",
    "\n",
    "for img_class in classes:\n",
    "    train_imgs.extend([file for file in os.listdir(train_folder+'/'+img_class) if file.endswith('.png')])\n",
    "    test_imgs.extend([file for file in os.listdir(test_folder+'/'+img_class) if file.endswith('.png')])\n",
    "    val_imgs.extend([file for file in os.listdir(val_folder+'/'+img_class) if file.endswith('.png')])\n",
    "    \n",
    "train_batch_size = len(train_imgs)\n",
    "test_batch_size = len(test_imgs)\n",
    "val_batch_size = len(val_imgs)\n",
    "\n",
    "print(train_batch_size)\n",
    "print(test_batch_size)\n",
    "print(val_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1399 images belonging to 3 classes.\n",
      "Found 352 images belonging to 3 classes.\n",
      "Found 437 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator().flow_from_directory(\n",
    "                        output_folder+'/train', target_size=(300, 200), batch_size = train_batch_size)\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "                        output_folder+'/test', target_size=(300, 200), batch_size = test_batch_size) \n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "                        output_folder+'/val', target_size=(300, 200), batch_size = val_batch_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split image data into image and label variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate shape of image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape:  (1399, 300, 200, 3)\n",
      "Test images shape:  (352, 300, 200, 3)\n",
      "Val images shape:  (437, 300, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Train images shape: ', train_images.shape)\n",
    "print('Test images shape: ', test_images.shape)\n",
    "print('Val images shape: ', val_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate shape of label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels shape:  (1399, 3)\n",
      "Test labels shape:  (352, 3)\n",
      "Val labels shape:  (437, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Train labels shape: ', train_labels.shape)\n",
    "print('Test labels shape: ', test_labels.shape)\n",
    "print('Val labels shape: ', val_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate label class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set class distribution\n",
      "0    0.325232\n",
      "1    0.331665\n",
      "2    0.343102\n",
      "dtype: float32\n",
      "Test set class distribution\n",
      "0    0.326705\n",
      "1    0.332386\n",
      "2    0.340909\n",
      "dtype: float32\n",
      "Val set class distribution\n",
      "0    0.324943\n",
      "1    0.331808\n",
      "2    0.343249\n",
      "dtype: float32\n",
      "Overall class distribution\n",
      "0    0.325411\n",
      "1    0.331810\n",
      "2    0.342779\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "train_labels_df = pd.DataFrame(train_labels)\n",
    "test_labels_df = pd.DataFrame(test_labels)\n",
    "val_labels_df = pd.DataFrame(val_labels)\n",
    "total_labels_df = pd.concat([train_labels_df, test_labels_df, val_labels_df], axis=0)\n",
    "\n",
    "\n",
    "print('Train set class distribution')\n",
    "print(train_labels_df.mean())\n",
    "\n",
    "print('Test set class distribution')\n",
    "print(test_labels_df.mean())\n",
    "\n",
    "print('Val set class distribution')\n",
    "print(val_labels_df.mean())\n",
    "\n",
    "print('Overall class distribution')\n",
    "print(total_labels_df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot label class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_labels[:,0], (train_batch_size,1))\n",
    "test_y = np.reshape(test_labels[:,0], (test_batch_size,1))\n",
    "val_y = np.reshape(val_labels[:,0], (val_batch_size,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(300 ,200,  3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "44/44 [==============================] - 152s 3s/step - loss: nan - acc: 0.6362 - val_loss: nan - val_acc: 0.6733\n",
      "Epoch 2/2\n",
      "44/44 [==============================] - 141s 3s/step - loss: nan - acc: 0.6748 - val_loss: nan - val_acc: 0.6733\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=2,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(test_images, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedummy(label_list):\n",
    "    dedummy_list = []\n",
    "    for item in label_list:\n",
    "        if item[0] == 1:\n",
    "            dedummy_list.append(0)\n",
    "        elif item[1] == 1:\n",
    "            dedummy_list.append(1)\n",
    "        elif item[2] == 1:\n",
    "            dedummy_list.append(2)\n",
    "    return dedummy_list\n",
    "\n",
    "train_classes = dedummy(train_labels)\n",
    "test_classes = dedummy(test_labels)\n",
    "val_classes = dedummy(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1399, 180000)\n",
      "(352, 180000)\n",
      "(437, 180000)\n"
     ]
    }
   ],
   "source": [
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n",
    "print(val_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_labels[:,0], (train_batch_size,1))\n",
    "test_y = np.reshape(test_labels[:,0], (test_batch_size,1))\n",
    "val_y = np.reshape(val_labels[:,0], (val_batch_size,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
